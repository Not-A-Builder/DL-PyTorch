{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of CNNs?\n",
    "\n",
    "The main advantage of a CNN over a normal MLP (Multi-Layer Perceptron) is that instead of flattening a 2D image into a vector, we can actually feed as input the matrices to the CNNs.\n",
    "\n",
    "![cnn_v_mlp](img/cnn_v_mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what happens is that multiple portions of an image, are fed as input to hidden layers.  \n",
    "\n",
    "This is shown in this image of the digit 7.  \n",
    "The CNN actually visualises each of the 4 different colour-coded segments individually and trains itself accordingly.  \n",
    "\n",
    "![a](img/cnn_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Working\n",
    "\n",
    "We now have 2 collections of hidden nodes, according to the picture below.  \n",
    "Each of the 2 collections have nodes responsible for visualising and examining different portions of the image.  \n",
    "\n",
    "It is also good to have each of the hidden nodes within a collection to have a common group of weights.  \n",
    "The idea is that different regions within the image will share the same kind of information.  \n",
    "In other words, any pattern that's relevant towrads understanding the image, could appear anywhere within the image.  \n",
    "For instance, it is not mandatory for a photo of a cat, to have the face of the cat in the dead centre of the photo. The face could be anywhere, but then it would still be a photo of the cat, and our goal is to properly identify it.  \n",
    "\n",
    "![a](img/cnn3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A CNN can remember spatial information\n",
    "\n",
    "CNNs look at images as a whole or in patches and analyse groups of pixels at a time.  \n",
    "The key to preserving the spatial information is what is called the **convolutional layer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolutional layer applies a series of image filters also called Convolutional Kernels to an input image.\n",
    "\n",
    "![4](img/cnn4.png)\n",
    "\n",
    "The resulting filtered images have different appearances. The filters may have extracted features like the edges of objects or the colours that distinguish the different classes of images. \n",
    "\n",
    "![5](img/cnn5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in the case of digit recognition, this is how a CNN would perform its actions.\n",
    "\n",
    "![6](img/cnn6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters that define a Convoltuional Layer. \n",
    "\n",
    "##### This is important foundational knowledge.\n",
    "\n",
    "To detect changes in intensity in an image, you’ll be using and creating specific image filters that look at groups of pixels and react to alternating patterns of dark/light pixels. These filters produce an output that shows edges of objects and differing textures.  \n",
    "\n",
    "So, let’s take a closer look at these filters and see when they’re useful in processing images and identifying traits of interest.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency in Images\n",
    "\n",
    "We have an intuition of what frequency means when it comes to sound. High-frequency is a high pitched noise, like a bird chirp or violin. And low frequency sounds are low pitch, like a deep voice or a bass drum. For sound, frequency actually refers to how fast a sound wave is oscillating; oscillations are usually measured in cycles/s (Hz), and high pitches and made by high-frequency waves.  \n",
    "\n",
    "Examples of low and high-frequency sound waves are pictured below. On the y-axis is amplitude, which is a measure of sound pressure that corresponds to the perceived loudness of a sound and on the x-axis is time.  \n",
    "\n",
    "##### (Top image) a low frequency sound wave (bottom) a high frequency sound wave.\n",
    "\n",
    "![7](img/cnn7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High and Low Frequency\n",
    "\n",
    "Similarly, frequency in images is a **rate of change**. But, what does it means for an image to change? Well, images change in space, and a high frequency image is one where the intensity changes a lot. And the level of brightness changes quickly from one pixel to the next.   \n",
    "\n",
    "A low frequency image may be one that is relatively uniform in brightness or changes very slowly. This is easiest to see in an example.  \n",
    "\n",
    "##### High and Low Frequency Image Patterns\n",
    "\n",
    "![8](img/cnn8.png)\n",
    "\n",
    "Most images have both high-frequency and low-frequency components. In the image above, on the scarf and striped shirt, we have a high-frequency image pattern; this part changes very rapidly from one brightness to another. Higher up in this same image, we see parts of the sky and background that change very gradually, which is considered a smooth, low-frequency pattern.  \n",
    "\n",
    "**High-frequency components also correspond to the edges of objects in images**, which can help us classify those objects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
