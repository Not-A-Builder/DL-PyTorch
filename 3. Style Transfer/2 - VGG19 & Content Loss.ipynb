{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 Architecture\n",
    "\n",
    "This is a 19-layer VGG network.  \n",
    "\n",
    ">It usually refers to a deep convolutional network for object recognition developed and trained by Oxford's renowned Visual Geometry Group (VGG). \n",
    ">It achieved very good performance on the ImageNet dataset.\n",
    "\n",
    "Here the first layer takes as input a coloured image and passes it through 5 convolutional layers, each separated from another by maxpooling layers and then passes the output through 3 fully-connected layers.    \n",
    "The first convolotuional layer is labelled conv1_1 and the deepest convolutional layer is labelled conv5_4.  \n",
    "\n",
    "![2](img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Representation\n",
    "\n",
    "It is important that the Content Representation of the target image is almost equal to the Content Representation of the original image, even as the target image starts to change its style.\n",
    "\n",
    "![3](img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Loss\n",
    "\n",
    "A formal way to represent the difference between the Content Representation of the original ($C_{c}$) and the target image ($T_{c}$).  [#LaTeX]\n",
    "\n",
    "![4](img/4.png)\n",
    "\n",
    "However we are not training the CNN at all, since our goal is not to minimse the classification error. Instead the only value we are tweaking is the content representation of the target image.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
